########################################
# LLM Providers (choose one and set keys)
########################################

# OpenAI
OPENAI_API_KEY=
# Optional base URLs (some integrations use one or the other)
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_API_BASE=https://api.openai.com/v1

# OpenRouter (alternative router for many models via OpenAI SDK)
# If set, OpenAI client will use OpenRouter instead of OPENAI_API_KEY
OPENROUTER_API_KEY=
# OPENROUTER_API_BASE=https://openrouter.ai/api/v1

# Google Gemini
GOOGLE_API_KEY=

# Anthropic
ANTHROPIC_API_KEY=
# Optional custom base URL
# ANTHROPIC_API_BASE=

# Groq
GROQ_API_KEY=

# Together AI
TOGETHER_API_KEY=

# DeepSeek
DEEPSEEK_API_KEY=
# DEEPSEEK_API_BASE=https://api.deepseek.com

# xAI (Grok)
XAI_API_KEY=
# XAI_API_BASE=https://api.x.ai/v1

# Azure OpenAI
LLM_AZURE_OPENAI_API_KEY=
LLM_AZURE_DEPLOYMENT=
LLM_AZURE_ENDPOINT=
LLM_AZURE_API_VERSION=

# vLLM (OpenAI-compatible server)
VLLM_API_KEY=
VLLM_BASE_URL=

# LM Studio (OpenAI-compatible local server)
# LMSTUDIO_BASE_URL=http://localhost:1234/v1

# Ollama (local server)
# OLLAMA_BASE_URL=http://localhost:11434

# AWS Bedrock (uses standard AWS credentials/env)
# AWS_ACCESS_KEY_ID=
# AWS_SECRET_ACCESS_KEY=
# AWS_SESSION_TOKEN=
# AWS_REGION=us-west-2

########################################
# Vector/Graph Stores
########################################

# Qdrant (Vector store)
MEMORY_QDRANT_HOST=qdrant
MEMORY_QDRANT_PORT=6333
MEMORY_QDRANT_COLLECTION_NAME=memories

# Memgraph (Graph store)
MEMORY_MEMGRAPH_URI=bolt://memgraph:7687
MEMORY_MEMGRAPH_USERNAME=memory_graph_user
MEMORY_MEMGRAPH_PASSWORD=mem0ry_graph_P@ss

# Optional: local history SQLite path used by server
# MEMORY_HISTORY_DB_PATH=/app/history/history.db
